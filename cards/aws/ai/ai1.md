https://vivek-aws.medium.com/aws-certified-ai-practitioner-2c4f8b01baa7
 
**Domain 1: Fundamentals of AI and ML.**

<!-- Card Start -->

### Front

What is the primary difference between AI and ML?  
- A. AI is a subset of ML  
- B. ML is a subset of AI  
- C. They are completely unrelated fields  
- D. AI and ML are the same thing

### Back

**Correct Answer**: B  
Explanation: ML is a subset of AI. The study guide mentions that understanding the similarities and differences between AI, ML, and deep learning is important (Task Statement 1.1).

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a type of machine learning?  
- A. Supervised learning  
- B. Unsupervised learning  
- C. Reinforcement learning  
- D. Diagnostic learning

### Back

**Correct Answer**: D  
Explanation: The study guide mentions supervised, unsupervised, and reinforcement learning as types of machine learning (Task Statement 1.1). Diagnostic learning is not a standard type of ML.

<!-- Card End -->
<!-- Card Start -->

### Front

What type of data is most suitable for training a computer vision model?  
- A. Tabular data  
- B. Time-series data  
- C. Image data  
- D. Text data

### Back

**Correct Answer**: C  
Explanation: Image data is most suitable for computer vision models. The study guide mentions different types of data used in AI models, including image data (Task Statement 1.1).

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is best suited for natural language processing tasks?  
- A. Amazon SageMaker  
- B. Amazon Comprehend  
- C. Amazon Polly  
- D. Amazon Transcribe

### Back

**Correct Answer**: B  
Explanation: Amazon Comprehend is specifically designed for natural language processing tasks. The study guide lists various AWS managed AI/ML services and their capabilities (Task Statement 1.2).

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of exploratory data analysis (EDA) in the ML development lifecycle?  
- A. To train the model  
- B. To deploy the model  
- C. To understand the characteristics of the data  
- D. To monitor the model in production

### Back

**Correct Answer**: C  
Explanation: EDA is used to understand the characteristics of the data before model training. The study guide mentions EDA as a component of an ML pipeline (Task Statement 1.3).

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical stage in an ML pipeline?  
- A. Data collection  
- B. Feature engineering  
- C. Model training  
- D. Customer acquisition

### Back

**Correct Answer**: D  
Explanation: Customer acquisition is not a typical stage in an ML pipeline. The study guide lists the components of an ML pipeline, which do not include customer acquisition (Task Statement 1.3).

<!-- Card End -->
<!-- Card Start -->

### Front

What does AUC stand for in the context of model performance metrics?  
- A. Average User Cost  
- B. Area Under the Curve  
- C. Automated Universal Calculation  
- D. Augmented Use Case

### Back

**Correct Answer**: B  
Explanation: AUC stands for Area Under the Curve (specifically, the ROC curve). The study guide mentions AUC as one of the model performance metrics (Task Statement 1.3).

<!-- Card End -->
<!-- Card Start -->

### Front

Which type of learning is most appropriate when you have a large dataset of labeled examples?  
- A. Unsupervised learning  
- B. Reinforcement learning  
- C. Supervised learning  
- D. Semi-supervised learning

### Back

**Correct Answer**: C  
Explanation: Supervised learning is most appropriate when you have labeled data. The study guide describes supervised learning as one of the types of machine learning (Task Statement 1.1).

<!-- Card End -->
<!-- Card Start -->

### Front

What is the main advantage of using pre-trained models?  
- A. They always perform better than custom models  
- B. They require less computational resources to train  
- C. They are always more accurate  
- D. They can be used immediately without any training data

### Back

**Correct Answer**: D  
Explanation: Pre-trained models can be used immediately without training data, which is their main advantage. The study guide mentions pre-trained models as a source of ML models (Task Statement 1.3).

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is best suited for automating the process of identifying the best hyperparameters for a model?  
- A. Amazon SageMaker Autopilot  
- B. Amazon Comprehend  
- C. Amazon Polly  
- D. Amazon Transcribe

### Back

**Correct Answer**: A  
Explanation: Amazon SageMaker Autopilot is designed for automating the process of finding the best hyperparameters. While not explicitly mentioned in the study guide, it falls under the SageMaker suite of tools discussed in Task Statement 1.2 and 1.3.

<!-- Card End -->
<!-- Card Start -->

### Front

What does MLOps stand for?  
- A. Machine Learning Operations  
- B. Multiple Learning Optimizations  
- C. Model Learning Objectives  
- D. Managed Learning Outputs

### Back

**Correct Answer**: A  
Explanation: MLOps stands for Machine Learning Operations. The study guide mentions MLOps and its fundamental concepts (Task Statement 1.3).

<!-- Card End -->


<!-- Card Start -->

### Front

Which of the following is NOT a typical business metric for evaluating ML models?  
- A. Cost per user  
- B. Development costs  
- C. Customer feedback  
- D. F1 score

### Back

**Correct Answer**: D  
Explanation: F1 score is a model performance metric, not a business metric. The study guide distinguishes between model performance metrics and business metrics (Task Statement 1.3).

**Business Metrics**:
- Cost per user (operational costs)
- Development costs (resource allocation)
- Customer feedback (satisfaction)
- Customer retention rate (business impact)
- Revenue generated
- Time-to-market
- ROI

**Model Performance Metrics**:
- F1 score (precision-recall trade-off)
- Accuracy
- AUC-ROC
- Mean Square Error
- BLEU score (for text generation)

Task Statement 1.3 emphasizes the importance of understanding both types of metrics for comprehensive model evaluation.


<!-- Card End -->


<!-- Card Start -->

### Front

Which of the following are considered business metrics for AI model evaluation? (Choose 2)
- A. Precision score
- B. Customer satisfaction score
- C. Mean Average Precision
- D. Time-to-value
- E. Root Mean Square Error

### Back

**Correct Answer**: B and D
**Explanation**: According to Task Statement 1.3, business metrics focus on real-world impact and value delivery:

**Business Metrics Selected**:
- Customer satisfaction score (B) - Measures actual user experience
- Time-to-value (D) - Measures how quickly the solution delivers business benefits

**Model Performance Metrics (NOT Business)**:
- Precision score (A) - Technical accuracy metric
- Mean Average Precision (C) - Statistical performance metric
- Root Mean Square Error (E) - Mathematical error measurement

<!-- Card End -->

<!-- Card Start -->

### Front

When evaluating an AI solution's success, what types of metrics should be considered? (Choose 2)
- A. Only technical performance metrics
- B. Return on Investment (ROI)
- C. Only user feedback
- D. Model inference latency
- E. Impact on business processes

### Back

**Correct Answer**: B and E
**Explanation**: Task Statement 1.3 emphasizes the need to evaluate AI solutions using both technical and business perspectives:

**Selected Metrics**:
- ROI (B) - Measures financial return against investment
- Impact on business processes (E) - Measures operational improvements

**Business Impact Considerations**:
- Cost savings
- Process efficiency gains
- Revenue generation
- Customer satisfaction
- Operational improvements

The key is balancing technical performance with actual business value delivery.

<!-- Card End -->

<!-- Card Start -->

### Front

What type of learning is most appropriate when you want an agent to learn from its interactions with an environment?  
- A. Supervised learning  
- B. Unsupervised learning  
- C. Reinforcement learning  
- D. Transfer learning

### Back

**Correct Answer**: C  
Explanation: Reinforcement learning is used when an agent learns from interactions with an environment. The study guide mentions reinforcement learning as one of the types of machine learning (Task Statement 1.1).

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is best suited for converting text to speech?  
- A. Amazon Comprehend  
- B. Amazon Translate  
- C. Amazon Transcribe  
- D. Amazon Polly

### Back

**Correct Answer**: D  
Explanation: Amazon Polly is designed for text-to-speech conversion. The study guide lists various AWS managed AI/ML services and their capabilities (Task Statement 1.2).

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of feature engineering in the ML development lifecycle?  
- A. To collect more data  
- B. To create new features or transform existing ones to improve model performance  
- C. To evaluate the model’s performance  
- D. To deploy the model to production

### Back

**Correct Answer**: B  
Explanation: Feature engineering involves creating new features or transforming existing ones to improve model performance. The study guide mentions feature engineering as a component of an ML pipeline (Task Statement 1.3).

<!-- Card End -->

 
<!-- Card Start -->

### Front

Which of the following is an example of unsupervised learning?  
- A. Spam detection  
- B. Image classification  
- C. Clustering customer segments  
- D. Predicting house prices

### Back

**Correct Answer**: C  
**Explanation**: In unsupervised learning, algorithms find patterns in unlabeled data. Clustering customer segments is a classic unsupervised learning task because it discovers natural groupings in data without predefined labels. The other options are supervised learning tasks because they require labeled data:
- Spam detection (A) needs labeled examples of spam and non-spam
- Image classification (B) requires images labeled with their categories
- House price prediction (D) needs historical prices as target values

In AWS, common unsupervised learning use cases include:
- Customer segmentation in Amazon Personalize
- Anomaly detection in Amazon Lookout for Metrics
- Topic modeling in Amazon Comprehend
- Dimensionality reduction for visualization

Task Statement 1.1 emphasizes understanding the fundamental differences between supervised and unsupervised learning approaches.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the main difference between batch inferencing and real-time inferencing?  
- A. Batch inferencing is always more accurate  
- B. Real-time inferencing can only be done on small datasets  
- C. Batch inferencing processes multiple inputs at once, while real-time inferencing processes individual inputs as they arrive  
- D. Real-time inferencing is always faster than batch inferencing

### Back

**Correct Answer**: C  
Explanation: The main difference is in how inputs are processed. The study guide mentions different types of inferencing, including batch and real-time (Task Statement 1.1).

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is best suited for managing the entire machine learning lifecycle?  
- A. Amazon Comprehend  
- B. Amazon SageMaker  
- C. Amazon Polly  
- D. Amazon Translate

### Back

**Correct Answer**: B  
Explanation: Amazon SageMaker is designed to manage the entire machine learning lifecycle. The study guide mentions SageMaker multiple times in the context of the ML development lifecycle (Task Statement 1.3).

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of model monitoring in production?  
- A. To train new models  
- B. To collect more data  
- C. To detect issues like model drift or data drift  
- D. To perform feature engineering

### Back

**Correct Answer**: C  
Explanation: Model monitoring in production is primarily used to detect issues like model drift or data drift. The study guide mentions model monitoring as part of MLOps (Task Statement 1.3).

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical use case for AI/ML?  
- A. Fraud detection  
- B. Recommendation systems  
- C. Manual data entry  
- D. Speech recognition

### Back

**Correct Answer**: C  
Explanation: Manual data entry is not a typical use case for AI/ML. The study guide lists several real-world AI applications, which do not include manual data entry (Task Statement 1.2).

<!-- Card End -->

Below are series of practice questions tailored to Domain 2. Each question is designed to test your knowledge and ensure you’re well-prepared for this critical section of the exam.

**Domain 2: Fundamentals of Generative AI.**

<!-- Card Start -->

### Front

What is a token in the context of generative AI?  
- A. A security feature  
- B. A unit of text processed by the model  
- C. A type of neural network  
- D. A model evaluation metric

### Back

**Correct Answer**: B  
Explanation: In generative AI, a token is a unit of text processed by the model. This is mentioned in Task Statement 2.1 under foundational generative AI concepts.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical use case for generative AI models?  
- A. Image generation  
- B. Summarization  
- C. Data encryption  
- D. Code generation

### Back

**Correct Answer**: C  
Explanation: Data encryption is not a typical use case for generative AI models. The other options are mentioned in Task Statement 2.1 as potential use cases.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary advantage of generative AI’s adaptability?  
- A. It can only work with structured data  
- B. It can handle a wide range of tasks and domains  
- C. It always produces perfect results  
- D. It eliminates the need for human oversight

### Back

**Correct Answer**: B  
Explanation: Adaptability in generative AI refers to its ability to handle a wide range of tasks and domains. This is mentioned in Task Statement 2.2 as one of the advantages of generative AI.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a hallucination in the context of generative AI?  
- A. A visual output produced by the model  
- B. A type of model architecture  
- C. An incorrect or fabricated output presented as fact  
- D. A method of model training

### Back

**Correct Answer**: C  
Explanation: Hallucinations refer to incorrect or fabricated outputs presented as fact by generative AI models. This is listed as a disadvantage of generative AI solutions in Task Statement 2.2.

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is designed specifically for developing generative AI applications?  
- A. Amazon EC2  
- B. Amazon S3  
- C. Amazon Bedrock  
- D. Amazon RDS

### Back

**Correct Answer**: C  
Explanation: Amazon Bedrock is mentioned in Task Statement 2.3 as an AWS service for developing generative AI applications.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a foundation model in generative AI?  
- A. A model that can only generate text  
- B. A large, pre-trained model that can be adapted for various tasks  
- C. A model specifically designed for image generation  
- D. A model that requires no training data

### Back

**Correct Answer**: B  
Explanation: A foundation model is a large, pre-trained model that can be adapted for various tasks. This concept is mentioned in Task Statement 2.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a stage in the foundation model lifecycle?  
- A. Data selection  
- B. Pre-training  
- C. Deployment  
- D. Marketing

### Back

**Correct Answer**: D  
Explanation: Marketing is not a stage in the foundation model lifecycle. The other options are mentioned in Task Statement 2.1 as part of the foundation model lifecycle.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary advantage of using AWS generative AI services for building applications?  
- A. They are always free  
- B. They provide a lower barrier to entry  
- C. They guarantee 100% accuracy  
- D. They eliminate the need for any coding

### Back

**Correct Answer**: B  
Explanation: A lower barrier to entry is mentioned in Task Statement 2.3 as one of the advantages of using AWS generative AI services.

<!-- Card End -->
<!-- Card Start -->

### Front

What is prompt engineering in the context of generative AI?  
- A. A method of hardware optimization  
- B. A technique for designing the physical structure of AI models  
- C. The process of crafting effective input prompts to guide model outputs  
- D. A way to reduce energy consumption in AI systems

### Back

**Correct Answer**: C  
Explanation: Prompt engineering refers to the process of crafting effective input prompts to guide model outputs. This is mentioned in Task Statement 2.1 as a foundational generative AI concept.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is a potential disadvantage of generative AI solutions?  
- A. Adaptability  
- B. Responsiveness  
- C. Inaccuracy  
- D. Simplicity

### Back

**Correct Answer**: C  
Explanation: Inaccuracy is listed as a potential disadvantage of generative AI solutions in Task Statement 2.2.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a multi-modal model in generative AI?  
- A. A model that can only process text data  
- B. A model that can work with multiple types of data (e.g., text, images, audio)  
- C. A model that requires multiple GPUs to run  
- D. A model that can only generate images

### Back

**Correct Answer**: B  
Explanation: A multi-modal model can work with multiple types of data. This is mentioned in Task Statement 2.1 under foundational generative AI concepts.

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service provides a playground for experimenting with generative AI models?  
- A. Amazon SageMaker  
- B. Amazon Comprehend  
- C. PartyRock  
- D. Amazon Polly

### Back

**Correct Answer**: C  
Explanation: PartyRock, an Amazon Bedrock Playground, is mentioned in Task Statement 2.3 as a service for developing generative AI applications.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a key consideration when selecting an appropriate generative AI model for a business problem?  
- A. The model’s popularity on social media  
- B. The model’s performance requirements  
- C. The model’s development date  
- D. The model’s country of origin

### Back

**Correct Answer**: B  
Explanation: Performance requirements are mentioned in Task Statement 2.2 as one of the factors to consider when selecting appropriate generative AI models.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical business metric for evaluating generative AI applications?  
- A. Conversion rate  
- B. Average revenue per user  
- C. Customer lifetime value  
- D. Model parameter count

### Back

**Correct Answer**: D  
Explanation: Model parameter count is not a business metric. The other options are mentioned in Task Statement 2.2 as business metrics for generative AI applications.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a key benefit of AWS infrastructure for generative AI applications?  
- A. It eliminates the need for any security measures  
- B. It provides unlimited free computing resources  
- C. It ensures compliance with relevant regulations  
- D. It guarantees that AI models will never make mistakes

### Back

**Correct Answer**: C  
Explanation: Compliance is mentioned in Task Statement 2.3 as one of the benefits of AWS infrastructure for generative AI applications.

<!-- Card End -->
<!-- Card Start -->

### Front

What is chunking in the context of generative AI?  
- A. A method of data compression  
- B. A technique for breaking down large inputs into smaller, manageable pieces  
- C. A type of model architecture  
- D. A way to increase model accuracy

### Back

**Correct Answer**: B  
Explanation: Chunking refers to breaking down large inputs into smaller, manageable pieces. This is mentioned in Task Statement 2.1 under foundational generative AI concepts.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is a key advantage of generative AI’s simplicity?  
- A. It always produces perfect results  
- B. It requires no human input  
- C. It can be easier to implement and use compared to traditional methods  
- D. It eliminates the need for data preprocessing

### Back

**Correct Answer**: C  
Explanation: Simplicity in generative AI often means it can be easier to implement and use compared to traditional methods. This is implied in Task Statement 2.2 where simplicity is listed as an advantage.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a diffusion model in generative AI?  
- A. A model that only works with textual data  
- B. A type of generative model often used for image generation  
- C. A model that requires no training data  
- D. A model specifically designed for natural language processing

### Back

**Correct Answer**: B  
Explanation: Diffusion models are a type of generative model often used for image generation. This is mentioned in Task Statement 2.1 under foundational generative AI concepts.

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is designed to provide conversational AI capabilities?  
- A. Amazon Bedrock  
- B. Amazon SageMaker  
- C. Amazon Q  
- D. Amazon S3

### Back

**Correct Answer**: C  
Explanation: Amazon Q is mentioned in Task Statement 2.3 as an AWS service for developing generative AI applications, and it provides conversational AI capabilities.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a key consideration in the cost tradeoffs of AWS generative AI services?  
- A. The color scheme of the user interface  
- B. The number of employees in the company  
- C. Token-based pricing  
- D. The physical location of the data center

### Back

**Correct Answer**: C  
Explanation: Token-based pricing is mentioned in Task Statement 2.3 as one of the cost tradeoffs to consider for AWS generative AI services.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of embeddings in generative AI?  
- A. To compress data for storage  
- B. To represent data in a high-dimensional space  
- C. To encrypt sensitive information  
- D. To generate random numbers

### Back

**Correct Answer**: B  
Explanation: Embeddings are used to represent data in a high-dimensional space. This is mentioned in Task Statement 2.1 under foundational generative AI concepts.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical use case for generative AI in customer service?  
- A. Chatbots  
- B. Automated email responses  
- C. Physical robot assistants  
- D. FAQ generation

### Back

**Correct Answer**: C  
Explanation: Physical robot assistants are not a typical use case for generative AI in customer service. The other options align with the use cases mentioned in Task Statement 2.1.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a key advantage of using AWS generative AI services for building applications in terms of development speed?  
- A. They automatically write all the code for you  
- B. They provide faster time to market  
- C. They eliminate the need for testing  
- D. They guarantee instant deployment

### Back

**Correct Answer**: B  
Explanation: Speed to market is mentioned in Task Statement 2.3 as one of the advantages of using AWS generative AI services.

<!-- Card End -->
<!-- Card Start -->

### Front

What is nondeterminism in the context of generative AI?  
- A. A type of model architecture  
- B. A method of data preprocessing  
- C. The property of producing different outputs for the same input  
- D. A technique for improving model accuracy

### Back

**Correct Answer**: C  
Explanation: Nondeterminism refers to the property of producing different outputs for the same input. This is listed as a potential disadvantage of generative AI in Task Statement 2.2.

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is designed to help developers quickly get started with pre-trained models for generative AI?  
- A. Amazon EC2  
- B. Amazon SageMaker JumpStart  
- C. Amazon RDS  
- D. Amazon CloudFront

### Back

**Correct Answer**: B  
Explanation: Amazon SageMaker JumpStart is mentioned in Task Statement 2.3 as an AWS service for developing generative AI applications, specifically designed to help developers quickly get started with pre-trained models.

<!-- Card End -->

Below, you’ll find a set of carefully crafted practice questions focused on Domain 3. These questions will challenge your understanding and help you prepare for the real exam, ensuring you’re ready to handle the practical aspects of applying foundation models.

**Domain 3: Applications of Foundation Models**

<!-- Card Start -->

### Front

What is Retrieval Augmented Generation (RAG)?  
- A. A technique for generating new data  
- B. A method of combining retrieved information with model generation  
- C. A type of model architecture  
- D. A data compression algorithm

### Back

**Correct Answer**: B  
Explanation: RAG is a method of combining retrieved information with model generation, as mentioned in Task Statement 3.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is suitable for storing embeddings in a vector database?  
- A. Amazon S3  
- B. Amazon RDS  
- C. Amazon OpenSearch Service  
- D. Amazon EC2

### Back

**Correct Answer**: C  
Explanation: Amazon OpenSearch Service is mentioned in Task Statement 3.1 as a service for storing embeddings in vector databases.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of adjusting the temperature parameter in inference?  
- A. To control the physical temperature of the server  
- B. To adjust the creativity or randomness of the model’s output  
- C. To increase the model’s processing speed  
- D. To reduce energy consumption

### Back

**Correct Answer**: B  
Explanation: The temperature parameter affects the creativity or randomness of the model’s output, as implied in Task Statement 3.1 under inference parameters.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a chain-of-thought prompt?  
- A. A physical chain used in AI hardware  
- B. A prompt that encourages the model to show its reasoning process  
- C. A method of linking multiple AI models  
- D. A technique for encrypting prompts

### Back

**Correct Answer**: B  
Explanation: Chain-of-thought is a prompt engineering technique that encourages the model to show its reasoning process, as mentioned in Task Statement 3.2.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical method for fine-tuning a foundation model?  
- A. Instruction tuning  
- B. Transfer learning  
- C. Physical tuning  
- D. Continuous pre-training

### Back

**Correct Answer**: C  
Explanation: Physical tuning is not a method for fine-tuning foundation models. The other options are mentioned in Task Statement 3.3.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the ROUGE metric used for in evaluating foundation models?  
- A. Measuring the redness of the model’s output  
- B. Evaluating the quality of generated summaries  
- C. Calculating the model’s energy efficiency  
- D. Determining the model’s processing speed

### Back

**Correct Answer**: B  
Explanation: ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is used for evaluating the quality of generated summaries, as mentioned in Task Statement 3.4.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of using Agents for Amazon Bedrock?  
- A. To hire human agents for AI tasks  
- B. To handle multi-step tasks in AI applications  
- C. To physically maintain AI hardware  
- D. To reduce the cost of AI services

### Back

**Correct Answer**: B  
Explanation: Agents for Amazon Bedrock are used to handle multi-step tasks in AI applications, as mentioned in Task Statement 3.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is a key consideration when selecting a pre-trained model?  
- A. The model’s popularity on social media  
- B. The physical size of the server hosting the model  
- C. The model’s input/output length capabilities  
- D. The color scheme of the model’s documentation

### Back

**Correct Answer**: C  
Explanation: The model’s input/output length capabilities are a key consideration when selecting a pre-trained model, as mentioned in Task Statement 3.1.

<!-- Card End -->
<!-- Card Start -->

### Front

What is prompt hijacking in the context of prompt engineering?  
- A. A method of optimizing prompts  
- B. A technique for stealing prompts from competitors  
- C. An attack where the model is tricked into ignoring the intended prompt  
- D. A way to speed up prompt processing

### Back

**Correct Answer**: C  
Explanation: Prompt hijacking is a risk where the model is tricked into ignoring the intended prompt, as implied in Task Statement 3.2 under potential risks of prompt engineering.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary goal of instruction tuning in foundation models?  
- A. To teach the model to follow specific instructions  
- B. To reduce the model’s size  
- C. To increase the model’s processing speed  
- D. To change the model’s programming language

### Back

**Correct Answer**: A  
Explanation: Instruction tuning aims to teach the model to follow specific instructions, as mentioned in Task Statement 3.3.

<!-- Card End -->
<!-- Card Start -->

### Front

What is BERTScore used for in evaluating foundation models?  
- A. Measuring the model’s energy efficiency  
- B. Evaluating the quality of generated text  
- C. Calculating the model’s processing speed  
- D. Determining the model’s market value

### Back

**Correct Answer**: B  
Explanation: BERTScore is used for evaluating the quality of generated text, as mentioned in Task Statement 3.4.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a key benefit of using in-context learning for foundation model customization?  
- A. It requires no additional training data  
- B. It always produces perfect results  
- C. It reduces the model’s size  
- D. It eliminates the need for prompts

### Back

**Correct Answer**: A  
Explanation: In-context learning allows for model customization without additional training data, as covered in Task Statement 3.1. Key points about in-context learning:

1. **What It Is**:
   - A technique where the model learns from examples provided in the prompt
   - Uses the context window to provide examples or instructions
   - Adapts the model's behavior without changing its weights

2. **Benefits**:
   - No need for separate training data or fine-tuning process
   - Quick to implement and test different approaches
   - Lower computational cost compared to fine-tuning
   - Flexible for different use cases within the same model
   - Immediate results without training infrastructure

3. **Common Approaches**:
   - Zero-shot: Direct instructions without examples
   - One-shot: Single example in the prompt
   - Few-shot: Multiple examples in the prompt

4. **Use Cases in AWS**:
   - Quick prototyping with Amazon Bedrock
   - Custom text generation tasks
   - Specialized classification without model training
   - Adapting foundation models for specific domains

5. **Limitations**:
   - Limited by the model's context window size
   - May not perform as well as fine-tuned models for complex tasks
   - Results can vary based on prompt quality
   - Requires more tokens per inference

Task Statement 3.1 emphasizes understanding these tradeoffs when choosing between in-context learning and other customization approaches.

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is suitable for storing embeddings in a relational database?  
- A. Amazon DynamoDB  
- B. Amazon S3  
- C. Amazon Aurora  
- D. Amazon EC2

### Back

**Correct Answer**: C  
Explanation: Amazon Aurora is mentioned in Task Statement 3.1 as a service for storing embeddings in databases.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a key consideration when evaluating whether a foundation model effectively meets business objectives?  
- A. The model’s popularity on social media  
- B. The physical size of the server hosting the model  
- C. The model’s impact on user engagement  
- D. The color scheme of the model’s user interface

### Back

**Correct Answer**: C  
Explanation: The model’s impact on user engagement is a key consideration when evaluating business effectiveness, as mentioned in Task Statement 3.4.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of negative prompts in prompt engineering?  
- A. To make the model generate negative emotions  
- B. To tell the model what to avoid in its output  
- C. To reduce the model’s energy consumption  
- D. To decrease the model’s processing speed

### Back

**Correct Answer**: B  
Explanation: Negative prompts are used to tell the model what to avoid in its output, as implied in Task Statement 3.2 under concepts of prompt engineering.

<!-- Card End -->
<!-- Card Start -->

### Front

What is continuous pre-training in the context of foundation models?  
- A. A method of constantly retraining the model on new data  
- B. A technique for training models 24/7  
- C. A way to train models using continuous mathematics  
- D. A process of training models on a continuous physical surface

### Back

**Correct Answer**: A  
Explanation: Continuous pre-training involves constantly retraining the model on new data, as mentioned in Task Statement 3.3.

<!-- Card End -->
<!-- Card Start -->

### Front

What is prompt poisoning in the context of prompt engineering risks?  
- A. A method of optimizing prompts  
- B. A technique for improving prompt quality  
- C. An attack where malicious content is inserted into training data or prompts  
- D. A way to speed up prompt processing

### Back

**Correct Answer**: C  
Explanation: Prompt poisoning is an attack where malicious content is inserted into training data or prompts, as implied in Task Statement 3.2 under potential risks of prompt engineering.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the BLEU score used for in evaluating foundation models?  
- A. Measuring the model’s energy efficiency  
- B. Evaluating the quality of machine translations  
- C. Calculating the model’s processing speed  
- D. Determining the model’s market value

### Back

**Correct Answer**: B  
Explanation: BLEU (Bilingual Evaluation Understudy) is used for evaluating the quality of machine translations, as mentioned in Task Statement 3.4.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a key benefit of using transfer learning for foundation model customization?  
- A. It requires no additional training  
- B. It allows the model to leverage knowledge from one domain to another  
- C. It always produces perfect results  
- D. It reduces the model’s size to zero

### Back

**Correct Answer**: B  
Explanation: Transfer learning allows the model to leverage knowledge from one domain to another, as mentioned in Task Statement 3.3.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of model latent space in the context of prompt engineering?  
- A. To physically store the model  
- B. To represent the model’s internal understanding and knowledge  
- C. To increase the model’s processing speed  
- D. To reduce the model’s energy consumption

### Back

**Correct Answer**: B  
Explanation: The model latent space represents the model’s internal understanding and knowledge, as implied in Task Statement 3.2 under concepts of prompt engineering.

<!-- Card End -->

Below, you’ll find a curated set of practice questions specifically designed to help you grasp the key concepts of responsible AI. These questions will challenge your understanding and prepare you to handle this important aspect of the exam with confidence.

**Domain 4: Guidelines for Responsible AI**

<!-- Card Start -->

### Front

Which of the following is NOT a feature of responsible AI?  
- A. Fairness  
- B. Robustness  
- C. Profitability  
- D. Inclusivity

### Back

**Correct Answer**: C  
Explanation: Profitability is not listed as a feature of responsible AI. The other options are mentioned in Task Statement 4.1 as features of responsible AI.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of Guardrails for Amazon Bedrock?  
- A. To physically protect AI hardware  
- B. To identify and enforce responsible AI features  
- C. To increase model performance  
- D. To reduce energy consumption

### Back

**Correct Answer**: B  
Explanation: Guardrails for Amazon Bedrock is used to identify features of responsible AI, as mentioned in Task Statement 4.1.

<!-- Card End -->

 
<!-- Card Start -->

### Front

Which of the following is a key consideration in responsible model selection?  
- A. The model’s popularity  
- B. The model’s environmental impact  
- C. The model’s country of origin  
- D. The model’s color scheme

### Back

**Correct Answer**: B  
Explanation: Environmental considerations are mentioned in Task Statement 4.1 as a responsible practice for model selection.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a potential legal risk of working with generative AI?  
- A. Physical injury to users  
- B. Intellectual property infringement claims  
- C. Increased electricity bills  
- D. Reduced internet speed

### Back

**Correct Answer**: B  
Explanation: Intellectual property infringement claims are mentioned in Task Statement 4.1 as a potential legal risk of working with generative AI.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a characteristic of datasets important for responsible AI?  
- A. Inclusivity  
- B. Diversity  
- C. Size  
- D. Balanced representation

### Back

**Correct Answer**: C  
Explanation: While size can be important, it’s not specifically listed as a characteristic for responsible AI datasets. The other options are mentioned in Task Statement 4.1.

<!-- Card End -->
<!-- Card Start -->

### Front

What is overfitting in the context of AI models?  
- A. When a model performs too well on the training data but poorly on new data  
- B. When a model is too large to fit in memory  
- C. When a model generates outputs that are too long  
- D. When a model consumes too much energy

### Back

**Correct Answer**: A  
Explanation: Overfitting refers to when a model performs too well on training data but poorly on new data, as implied in Task Statement 4.1 under effects of bias and variance.

<!-- Card End -->
#fix
Add more to end
<!-- Card Start -->

### Front

Which AWS service is designed to help detect and monitor bias in machine learning models?  
- A. Amazon EC2  
- B. Amazon S3  
- C. Amazon SageMaker Clarify  
- D. Amazon RDS

### Back

**Correct Answer**: C  
Explanation: Amazon SageMaker Clarify is mentioned in Task Statement 4.1 as a tool to detect and monitor bias.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary difference between transparent and non-transparent AI models?  
- A. Transparent models are always more accurate  
- B. Transparent models allow for understanding of their decision-making process  
- C. Transparent models are always smaller in size  
- D. Transparent models consume less energy

### Back

**Correct Answer**: B  
Explanation: Transparent models allow for understanding of their decision-making process, as implied in Task Statement 4.2.

<!-- Card End -->
<!-- Card Start -->

### Front

Which tool can be used to document model information for transparency?  
- A. Amazon SageMaker Model Cards  
- B. Amazon EC2  
- C. Amazon S3  
- D. Amazon RDS

### Back

**Correct Answer**: A  
Explanation: Amazon SageMaker Model Cards are mentioned in Task Statement 4.2 as a tool to identify transparent and explainable models.

<!-- Card End -->
<!-- Card Start -->

### Front

What is a potential trade-off between model safety and transparency?  
- A. Safer models are always less transparent  
- B. Transparent models are always less safe  
- C. Increased transparency might reveal vulnerabilities  
- D. There are no trade-offs between safety and transparency

### Back

**Correct Answer**: C  
Explanation: Increased transparency might reveal vulnerabilities, which is a potential trade-off implied in Task Statement 4.2.

<!-- Card End -->
<!-- Card Start -->

### Front

What is human-centered design in the context of explainable AI?  
- A. Designing AI systems that look like humans  
- B. Creating AI systems that prioritize human needs and understanding  
- C. Using humans instead of AI for all tasks  
- D. Designing AI systems that can only be used by humans

### Back

**Correct Answer**: B  
Explanation: Human-centered design in explainable AI involves creating systems that prioritize human needs and understanding, as implied in Task Statement 4.2.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical effect of bias in AI systems?  
- A. Unfair treatment of certain demographic groups  
- B. Improved overall accuracy  
- C. Potential legal issues  
- D. Loss of user trust

### Back

**Correct Answer**: B  
Explanation: Improved overall accuracy is not typically an effect of bias. The other options are implied in Task Statement 4.1 under effects of bias and variance.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of subgroup analysis in responsible AI?  
- A. To divide the development team into subgroups  
- B. To analyze the model’s performance across different demographic groups  
- C. To reduce the model’s size  
- D. To increase the model’s processing speed

### Back

**Correct Answer**: B  
Explanation: Subgroup analysis is used to analyze the model’s performance across different demographic groups, as mentioned in Task Statement 4.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is a key consideration for dataset diversity in responsible AI?  
- A. Using data from only one source  
- B. Ensuring representation of various demographic groups  
- C. Using the largest dataset available regardless of content  
- D. Using only the most recent data

### Back

**Correct Answer**: B  
Explanation: Ensuring representation of various demographic groups is key for dataset diversity, as implied in Task Statement 4.1 under characteristics of datasets.

<!-- Card End -->
<!-- Card Start -->

### Front

What is veracity in the context of responsible AI?  
- A. The speed at which the AI system operates  
- B. The truthfulness and accuracy of the AI system’s outputs  
- C. The size of the AI model  
- D. The cost of running the AI system

### Back

**Correct Answer**: B  
Explanation: Veracity refers to the truthfulness and accuracy of the AI system’s outputs, as mentioned in Task Statement 4.1 as a feature of responsible AI.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical method for improving model interpretability?  
- A. Using simpler models  
- B. Providing feature importance rankings  
- C. Increasing the model’s size  
- D. Generating human-readable explanations

### Back

**Correct Answer**: C  
Explanation: Increasing the model’s size typically doesn’t improve interpretability. The other options are implied methods for improving interpretability in Task Statement 4.2.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of Amazon Augmented AI (A2I) in responsible AI?  
- A. To replace human workers with AI  
- B. To facilitate human review of AI predictions  
- C. To increase the AI model’s size  
- D. To reduce energy consumption of AI systems

### Back

**Correct Answer**: B  
Explanation: Amazon A2I is used to facilitate human review of AI predictions, as mentioned in Task Statement 4.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is a key consideration when evaluating the fairness of an AI system?  
- A. The system’s processing speed  
- B. The system’s energy consumption  
- C. The system’s impact on different demographic groups  
- D. The system’s popularity among users

### Back

**Correct Answer**: C  
Explanation: The system’s impact on different demographic groups is key when evaluating fairness, as implied in Task Statement 4.1 under effects of bias and variance.

<!-- Card End -->
<!-- Card Start -->

### Front

What is underfitting in the context of AI models?  
- A. When a model is too small to fit in memory  
- B. When a model performs poorly on both training and new data  
- C. When a model generates outputs that are too short  
- D. When a model consumes too little energy

### Back

**Correct Answer**: B  
Explanation: Underfitting refers to when a model performs poorly on both training and new data, as implied in Task Statement 4.1 under effects of bias and variance.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical benefit of using open source models for transparency?  
- A. Ability to inspect the model’s code  
- B. Community-driven improvements  
- C. Guaranteed perfect performance  
- D. Potential for independent audits

### Back

**Correct Answer**: C  
Explanation: Guaranteed perfect performance is not a typical benefit of open source models. The other options are implied benefits in Task Statement 4.2.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of analyzing label quality in responsible AI?  
- A. To improve the visual appearance of labels  
- B. To ensure the accuracy and consistency of data labels  
- C. To reduce the number of labels used  
- D. To increase the model’s processing speed

### Back

**Correct Answer**: B  
Explanation: Analyzing label quality is used to ensure the accuracy and consistency of data labels, as mentioned in Task Statement 4.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is a potential consequence of using biased datasets in AI training?  
- A. Improved model performance for all groups  
- B. Unfair or discriminatory outcomes for certain groups  
- C. Reduced energy consumption  
- D. Faster model training times

### Back

**Correct Answer**: B  
Explanation: Using biased datasets can lead to unfair or discriminatory outcomes for certain groups, as implied in Task Statement 4.1 under effects of bias and variance.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary goal of responsible practices in model selection?  
- A. To always choose the largest model available  
- B. To select models based solely on performance metrics  
- C. To balance performance with ethical considerations and sustainability  
- D. To choose the most expensive model

### Back

**Correct Answer**: C  
Explanation: Responsible model selection involves balancing performance with ethical considerations and sustainability, as implied in Task Statement 4.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical characteristic of a curated data source for responsible AI?  
- A. Verified accuracy  
- B. Known provenance  
- C. Largest possible size  
- D. Ethical collection methods

### Back

**Correct Answer**: C  
Explanation: The largest possible size is not necessarily a characteristic of a curated data source for responsible AI. The other options are implied in Task Statement 4.1 under characteristics of datasets.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of human audits in responsible AI systems?  
- A. To replace AI systems with human workers  
- B. To verify and validate AI system outputs and processes  
- C. To increase the AI system’s processing speed  
- D. To reduce the AI system’s energy consumption

### Back

**Correct Answer**: B  
Explanation: Human audits are used to verify and validate AI system outputs and processes, as mentioned in Task Statement 4.1.

<!-- Card End -->

Below, you’ll find the last set of practice questions specifically designed to reinforce your understanding of Domain 5. These questions will help solidify your knowledge and ensure you’re fully prepared for this crucial aspect of the exam.

**Domain 5: Security, Compliance, and Governance for AI Solutions**

<!-- Card Start -->

### Front

Which AWS service is primarily used for managing access and permissions for AI systems?  
- A. Amazon S3  
- B. AWS IAM  
- C. Amazon EC2  
- D. Amazon RDS

### Back

**Correct Answer**: B  
Explanation: AWS IAM (Identity and Access Management) is used for managing roles, policies, and permissions, as mentioned in Task Statement 5.1.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of Amazon Macie in AI security?  
- A. To generate AI models  
- B. To discover and protect sensitive data  
- C. To increase model performance  
- D. To reduce energy consumption

### Back

**Correct Answer**: B  
Explanation: Amazon Macie is used to discover and protect sensitive data, as mentioned in Task Statement 5.1.

<!-- Card End -->
<!-- Card Start -->

### Front

What does the AWS shared responsibility model refer to?  
- A. Sharing AI models between customers  
- B. Division of security responsibilities between AWS and the customer  
- C. Sharing costs between AWS and the customer  
- D. Dividing AI tasks between humans and machines

### Back

**Correct Answer**: B  
Explanation: The AWS shared responsibility model refers to the division of security responsibilities between AWS and the customer, as mentioned in Task Statement 5.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical method for securing AI systems?  
- A. Encryption  
- B. Access control  
- C. Public data sharing  
- D. Vulnerability management

### Back

**Correct Answer**: C  
Explanation: Public data sharing is not typically a method for securing AI systems. The other options are mentioned or implied in Task Statement 5.1.

<!-- Card End -->
<!-- Card Start -->

### Front

What is data lineage in the context of AI security?  
- A. A method of data encryption  
- B. Tracking the origin and transformations of data  
- C. A type of AI model architecture  
- D. A way to increase data processing speed

### Back

**Correct Answer**: B  
Explanation: Data lineage involves tracking the origin and transformations of data, as implied in Task Statement 5.1 under source citation and documenting data origins.

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is used for detecting security threats in AI systems?  
- A. Amazon Macie  
- B. Amazon S3  
- C. Amazon EC2  
- D. Amazon RDS

### Back

**Correct Answer**: A  
Explanation: While not explicitly stated for threat detection, Amazon Macie is mentioned in Task Statement 5.1 as a security service for AI systems and can be used for detecting security threats.

<!-- Card End -->
<!-- Card Start -->

### Front

What is prompt injection in the context of AI security?  
- A. A method of improving prompt quality  
- B. A security vulnerability where malicious input manipulates the AI’s behavior  
- C. A technique for speeding up AI processing  
- D. A way to reduce AI energy consumption

### Back

**Correct Answer**: B  
Explanation: Prompt injection is a security vulnerability where malicious input manipulates the AI’s behavior, as mentioned in Task Statement 5.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical regulatory compliance standard for AI systems?  
- A. ISO  
- B. SOC  
- C. HTML  
- D. Algorithm accountability laws

### Back

**Correct Answer**: C  
Explanation: HTML is not a regulatory compliance standard. The other options are mentioned in Task Statement 5.2 as regulatory compliance standards for AI systems.

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is used for continuous monitoring and assessment of resources?  
- A. Amazon EC2  
- B. AWS Config  
- C. Amazon S3  
- D. Amazon RDS

### Back

**Correct Answer**: B  
Explanation: AWS Config is mentioned in Task Statement 5.2 as a service for assisting with governance and regulation compliance, which includes continuous monitoring and assessment.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of AWS Artifact in AI governance?  
- A. To generate AI models  
- B. To provide access to AWS compliance reports  
- C. To increase model performance  
- D. To reduce energy consumption

### Back

**Correct Answer**: B  
Explanation: AWS Artifact provides access to AWS compliance reports, as implied in Task Statement 5.2.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT typically part of a data governance strategy?  
- A. Data lifecycle management  
- B. Data retention policies  
- C. Data public sharing policies  
- D. Data monitoring

### Back

**Correct Answer**: C  
Explanation: Data public sharing policies are not typically part of a data governance strategy for AI systems. The other options are mentioned in Task Statement 5.2.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of AWS CloudTrail in AI governance?  
- A. To generate AI models  
- B. To log API calls and account activity  
- C. To increase model performance  
- D. To reduce energy consumption

### Back

**Correct Answer**: B  
Explanation: AWS CloudTrail is used to log API calls and account activity, as mentioned in Task Statement 5.2.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is a key consideration in secure data engineering for AI?  
- A. Maximizing data collection without regard to quality  
- B. Implementing privacy-enhancing technologies  
- C. Making all data publicly accessible  
- D. Using only unencrypted data storage

### Back

**Correct Answer**: B  
Explanation: Implementing privacy-enhancing technologies is a key consideration in secure data engineering, as mentioned in Task Statement 5.1.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of the Generative AI Security Scoping Matrix?  
- A. To generate AI models  
- B. To provide a framework for assessing AI security risks  
- C. To increase model performance  
- D. To reduce energy consumption

### Back

**Correct Answer**: B  
Explanation: The Generative AI Security Scoping Matrix is mentioned in Task Statement 5.2 as a governance framework, implying its use in assessing AI security risks.

<!-- Card End -->
<!-- Card Start -->

### Front

Which AWS service is used for automated security assessments?  
- A. Amazon EC2  
- B. Amazon Inspector  
- C. Amazon S3  
- D. Amazon RDS

### Back

**Correct Answer**: B  
Explanation: Amazon Inspector is mentioned in Task Statement 5.2 as a service for assisting with governance and regulation compliance, which includes automated security assessments.

<!-- Card End -->
<!-- Card Start -->

### Front

What is data residency in the context of AI governance?  
- A. The physical location where data is stored  
- B. The duration for which data is kept  
- C. The speed at which data is processed  
- D. The format in which data is stored

### Back

**Correct Answer**: A  
Explanation: Data residency refers to the physical location where data is stored, as mentioned in Task Statement 5.2 under data governance strategies.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT a typical consideration in AI application security?  
- A. Threat detection  
- B. Vulnerability management  
- C. Maximizing public data sharing  
- D. Infrastructure protection

### Back

**Correct Answer**: C  
Explanation: Maximizing public data sharing is not typically a consideration in AI application security. The other options are mentioned in Task Statement 5.1.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of AWS Trusted Advisor in AI governance?  
- A. To generate AI models  
- B. To provide real-time guidance for improving AWS environment  
- C. To increase model performance  
- D. To reduce energy consumption

### Back

**Correct Answer**: B  
Explanation: AWS Trusted Advisor provides real-time guidance for improving the AWS environment, as mentioned in Task Statement 5.2.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is a key aspect of data integrity in AI systems?  
- A. Ensuring data remains unchanged and uncorrupted  
- B. Making all data publicly accessible  
- C. Using only the largest datasets available  
- D. Storing all data in a single location

### Back

**Correct Answer**: A  
Explanation: Ensuring data remains unchanged and uncorrupted is a key aspect of data integrity, as implied in Task Statement 5.1 under best practices for secure data engineering.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of encryption at rest in AI security?  
- A. To protect data while it’s being transmitted  
- B. To protect stored data  
- C. To increase data processing speed  
- D. To reduce energy consumption

### Back

**Correct Answer**: B  
Explanation: Encryption at rest is used to protect stored data, as mentioned in Task Statement 5.1.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT typically part of governance protocols for AI systems?  
- A. Regular policy reviews  
- B. Team training requirements  
- C. Maximizing model complexity  
- D. Transparency standards

### Back

**Correct Answer**: C  
Explanation: Maximizing model complexity is not typically part of governance protocols. The other options are mentioned in Task Statement 5.2.

<!-- Card End -->
<!-- Card Start -->

### Front

What is the primary purpose of AWS Audit Manager in AI governance?  
- A. To generate AI models  
- B. To continuously audit AWS usage for compliance  
- C. To increase model performance  
- D. To reduce energy consumption

### Back

**Correct Answer**: B  
Explanation: AWS Audit Manager is used to continuously audit AWS usage for compliance, as mentioned in Task Statement 5.2.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is a key consideration in AI infrastructure protection?  
- A. Maximizing public access to AI systems  
- B. Implementing network security measures  
- C. Using only the largest available models  
- D. Storing all data in a single location

### Back

**Correct Answer**: B  
Explanation: Implementing network security measures is a key consideration in AI infrastructure protection, as implied in Task Statement 5.1 under security considerations for AI systems.

<!-- Card End -->
#fix  add more contex
<!-- Card Start -->

### Front

What is the primary purpose of data cataloging in AI governance?  
- A. To make all data publicly accessible  
- B. To organize and inventory data assets  
- C. To increase data processing speed  
- D. To reduce data storage costs

### Back

**Correct Answer**: B  
Explanation: Data cataloging is used to organize and inventory data assets, as implied in Task Statement 5.1 under source citation and documenting data origins.

<!-- Card End -->
<!-- Card Start -->

### Front

Which of the following is NOT typically a component of a data lifecycle management strategy?  
- A. Data creation  
- B. Data retention  
- C. Data deletion  
- D. Data public sharing

### Back

**Correct Answer**: D  
Explanation: Data public sharing is not typically a component of a data lifecycle management strategy. The other options are implied in Task Statement 5.2 under data governance strategies.

<!-- Card End -->



